{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c02309d",
   "metadata": {},
   "source": [
    "### ğŸ§© Step 1: å¯¼å…¥å¿…è¦çš„åº“\n",
    "å¯¼å…¥å¤„ç†éŸ³é¢‘ã€ç»˜å›¾å’Œä¿¡å·å¤„ç†æ‰€éœ€çš„åº“ï¼Œå¯ä»¥è‡ªè¡Œæ·»åŠ æˆ–åˆ é™¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯æ ¹æ®éœ€è¦å¢åˆ åº“\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from python_speech_features import mfcc, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ce980",
   "metadata": {},
   "source": [
    "### ğŸµ Step 2: å®šä¹‰éŸ³é¢‘ç‰¹å¾æå–ç±» `WavtoMfcc`\n",
    "è¿™ä¸ªç±»ç”¨äºå°†è¯­éŸ³ä¿¡å·è½¬æ¢ä¸º MFCC ç‰¹å¾åºåˆ—ã€‚\n",
    "ä½ éœ€è¦åœ¨æ ‡æ³¨ `### START HERE ###` çš„éƒ¨åˆ†è¡¥å…¨æ»‘çª—é€»è¾‘å’Œç‰¹å¾æå–é€»è¾‘ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸€ä¸ªç±»ï¼Œè¾“å…¥wavè·¯å¾„ï¼Œè¾“å‡ºæ»‘çª—åçš„mfccç‰¹å¾æ•°ç»„ï¼Œç»´åº¦å‚æ•°ï¼Œçª—é•¿å‡å¯è‡ªå®šï¼Œè¿™è¾¹åªæ˜¯ä¸€ä¸ªdefault\n",
    "class WavtoMfcc(object):\n",
    "    def __init__(self, url, numceps=13, segment_len=1000, hop_len=1000):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        url - wavæ–‡ä»¶è·¯å¾„\n",
    "        numcep - å€’é¢‘è°±è¿”å›çš„æ•°é‡ï¼Œé»˜è®¤13ï¼Œå¯è°ƒ\n",
    "        segment_len - çª—é•¿ï¼Œä¸€ä¸ªçª—åŒ…å«å¤šå°‘ä¸ªé‡‡æ ·ç‚¹\n",
    "        hop_len - çª—ç§»ï¼Œç›¸é‚»ä¸¤çª—ä¹‹é—´çš„é—´éš”ï¼Œä¸€èˆ¬å°äºçª—é•¿ï¼Œè¿™é‡Œé€‰çš„æ˜¯ç­‰äºçª—é•¿\n",
    "        \n",
    "        Output:\n",
    "        None\n",
    "        \"\"\"\n",
    "        if segment_len <= 0 or hop_len <= 0:\n",
    "            raise ValueError(\"segment_len and hop_len must be positive\")\n",
    "        self.numceps = numceps\n",
    "        self.url = str(url)\n",
    "        self.sample_rate, self.signal = scipy.io.wavfile.read(self.url)\n",
    "        # Convert signal to float32 and force mono if multi-channel\n",
    "        self.signal = np.asarray(self.signal, dtype=np.float32)\n",
    "        if getattr(self.signal, 'ndim', 1) > 1:\n",
    "            # å¹³å‡æ‰€æœ‰é€šé“ä¸ºå•å£°é“ï¼ˆç®€å•ä¸”å¸¸ç”¨çš„å¤„ç†ï¼‰\n",
    "            self.signal = np.mean(self.signal, axis=1)\n",
    "        # å»é™¤ç›´æµåˆ†é‡ï¼Œæå‡MFCCçš„ç¨³å®šæ€§\n",
    "        if self.signal.size == 0:\n",
    "            raise ValueError(f\"Empty signal encountered in {self.url}\")\n",
    "        self.signal -= np.mean(self.signal)\n",
    "        self.segment = []\n",
    "        signal_len = len(self.signal)\n",
    "        \"\"\"\n",
    "        å®ç°é‡‡æ ·ç‚¹æ»‘çª—ï¼Œå­˜å…¥self.segment\n",
    "        \"\"\"\n",
    "        ### START HERE ###\n",
    "        for start in range(0, signal_len, hop_len):\n",
    "            end = start + segment_len\n",
    "            window = self.signal[start:end]\n",
    "            if len(window) < segment_len:\n",
    "                pad_width = segment_len - len(window)\n",
    "                window = np.pad(window, (0, pad_width), mode=\"reflect\")\n",
    "            # ç¡®ä¿æ¯ä¸ª window æ˜¯ä¸€ç»´æ•°ç»„\n",
    "            window = np.asarray(window, dtype=np.float32).reshape(-1)\n",
    "            self.segment.append(window)\n",
    "        if not self.segment:\n",
    "            self.segment.append(self.signal.copy())\n",
    "        ### END HERE ###\n",
    "        # å°† segment ä¿æŒä¸º listï¼ˆåç»­æŒ‰éœ€è½¬ä¸ºæ•°ç»„ï¼‰ï¼Œä»¥é¿å… numpy åœ¨ shape ä¸ç»Ÿä¸€æ—¶æŠ¥é”™\n",
    "        self.segment_len = len(self.segment)\n",
    "        self.feature = self.get_segment_mfcc()\n",
    "        self.feature = np.array(self.feature)\n",
    "        \n",
    "    def get_segment_mfcc(self):\n",
    "        '''\n",
    "        Input:\n",
    "        æ—  - å¯¹self.signalè¿›è¡Œå¤„ç†\n",
    "        \n",
    "        Output:\n",
    "        feature - å¯¹åº”çª—çš„mfccï¼Œè¿”å›ç»´åº¦å¯è‡ªåŠ¨è®¾è®¡ï¼Œä¸€èˆ¬ä¸º39\n",
    "        '''\n",
    "        feature = []\n",
    "        for window in self.segment:\n",
    "            wav_feature = mfcc(window, self.sample_rate, numcep=self.numceps, winlen=0.025, winstep=0.01,\n",
    "                               nfilt=26, nfft=2048, lowfreq=0, highfreq=None, preemph=0.97)\n",
    "            if wav_feature.size == 0:\n",
    "                feature.append(np.zeros(self.numceps * 3, dtype=np.float32))\n",
    "                continue\n",
    "            delta_feat = delta(wav_feature, 2)\n",
    "            delta_delta_feat = delta(delta_feat, 2)\n",
    "            stacked = np.hstack((wav_feature, delta_feat, delta_delta_feat))\n",
    "            # æ¯ä¸ª window èšåˆä¸ºä¸€ä¸ªå®šé•¿å‘é‡ï¼ˆå¯¹ frames åšå¹³å‡ï¼‰\n",
    "            feature.append(np.mean(stacked, axis=0))\n",
    "        feature = np.asarray(feature, dtype=np.float32)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WavtoMfcc object info:\n",
      "\n",
      "<class '__main__.WavtoMfcc'>\n",
      "Source not available via inspect.getsource. This can happen in some interactive environments.\n",
      "Printing available attributes and docstring instead:\n",
      "\n",
      "docstring: None\n",
      "members sample: ['get_segment_mfcc']\n",
      "\n",
      "Error instantiating WavtoMfcc:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ljy\\AppData\\Local\\Temp\\ipykernel_10608\\1032060857.py\", line 15, in <module>\n",
      "    sample_test = WavtoMfcc(wav_path1)\n",
      "                            ^^^^^^^^^\n",
      "NameError: name 'wav_path1' is not defined\n"
     ]
    }
   ],
   "source": [
    "# å¿«é€Ÿè¯Šæ–­ï¼šç¡®è®¤å†…å­˜ä¸­ WavtoMfcc å®šä¹‰ä¸æ–‡ä»¶ä¸€è‡´ï¼Œä»¥åŠèƒ½å¦å®ä¾‹åŒ–å•ä¸ªæ ·æœ¬ï¼ˆå®‰å…¨ç‰ˆï¼‰\n",
    "import inspect\n",
    "print('WavtoMfcc object info:\\n')\n",
    "print(repr(WavtoMfcc))\n",
    "try:\n",
    "    src = inspect.getsource(WavtoMfcc)\n",
    "    print('\\n'.join(src.splitlines()[:40]))\n",
    "except (OSError, IOError):\n",
    "    print('Source not available via inspect.getsource. This can happen in some interactive environments.')\n",
    "    print('Printing available attributes and docstring instead:\\n')\n",
    "    print('docstring:', getattr(WavtoMfcc, '__doc__', None))\n",
    "    print('members sample:', [k for k in dir(WavtoMfcc) if not k.startswith('_')][:20])\n",
    "# å°è¯•å®ä¾‹åŒ–ä¸€ä¸ªæ ·æœ¬ï¼Œæ•è·å¼‚å¸¸å¹¶æ‰“å°\n",
    "try:\n",
    "    sample_test = WavtoMfcc(wav_path1)\n",
    "    print('\\nInstantiated WavtoMfcc OK â€” feature shape:', getattr(sample_test, 'feature', None).shape)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print('\\nError instantiating WavtoMfcc:')\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde91a4",
   "metadata": {},
   "source": [
    "### âš™ï¸ Step 3: å®šä¹‰åŒ¹é…ä»£ä»·å‡½æ•° `cost`\n",
    "è¿™ä¸ªå‡½æ•°è®¡ç®—ä¸¤å¸§ç‰¹å¾ä¹‹é—´çš„è·ç¦»ï¼Œç”¨äº DTW è·¯å¾„è®¡ç®—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸¤ä¸ªmfccç‰¹å¾åŒ¹é…çš„cost\n",
    "def cost(x, y, metric=\"sqeuclidean\"):\n",
    "    if metric == \"sqeuclidean\":\n",
    "        return np.sum((x - y) ** 2)\n",
    "    if metric == \"euclidean\":\n",
    "        return np.linalg.norm(x - y)\n",
    "    if metric == \"cosine\":\n",
    "        denom = (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "        if denom == 0:\n",
    "            return 1.0\n",
    "        return 1.0 - float(np.dot(x, y) / denom)\n",
    "    raise ValueError(f\"Unsupported metric: {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦å­˜ä¸€ä¸ªæ ‡å‡†å‘½åï¼Œä»¥ä¾¿æ‰“åŒ…æäº¤\n",
    "# NOTE: plot_mfcc is defined later in the notebook.\n",
    "# The direct call was causing NameError when run before the function definition.\n",
    "# Commenting out the early call to avoid runtime error. If you want to save\n",
    "# an example MFCC figure, run the plotting cell after the function is defined.\n",
    "# plot_mfcc(Wav1, \"MFCC Feature (Sample)\", \"mfcc_feature.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"./data\")\n",
    "RESULT_ROOT = Path(\"../results\")\n",
    "RESULT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "wav_path1 = DATA_ROOT / \"data_en_train\" / \"digit_6\" / \"9_6.wav\"\n",
    "wav_path2 = DATA_ROOT / \"data_en_train\" / \"digit_6\" / \"10_6.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç®€å•æµ‹è¯•WavtoMfccç±»å’Œcostçš„ç»“æœ\n",
    "Wav1=WavtoMfcc(wav_path1)\n",
    "#f1=Wav1.get_segment_mfcc(np.array([1]))\n",
    "#print(f1.shape)\n",
    "Wav2=WavtoMfcc(wav_path2)\n",
    "#f2=Wav2.get_segment_mfcc(np.array([1,2]))\n",
    "#print(f2)\n",
    "#print(cost(f1,f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCC ç‰¹å¾å¯è§†åŒ–ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mfcc(wav_obj, title, save_name):\n",
    "    feature_map = wav_obj.feature\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    im = ax.imshow(feature_map.T, aspect='auto', origin='lower', cmap='magma')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Frame Index')\n",
    "    ax.set_ylabel('MFCC Coefficients')\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(RESULT_ROOT / save_name, dpi=150)\n",
    "    plt.close(fig)\n",
    "plot_mfcc(Wav1, \"Digit 6 Sample MFCC\", \"mfcc_digit6.png\")\n",
    "plot_mfcc(Wav2, \"Digit 6 Sample MFCC (Another Speaker)\", \"mfcc_digit6_alt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¢„å¤„ç†ä¸¤ä¸¤åŒ¹é…çš„costæ•°ç»„ï¼ˆPSï¼šåœ¨è¿™é‡Œå…¶å®å¹¶ä¸éå¸¸å¿…è¦ï¼Œå¤æ‚åº¦ä¸ç›´æ¥è°ƒç”¨ä»ç„¶æ˜¯ä¸€è‡´çš„ï¼Œå·®ä¸ªå¸¸æ•°ï¼‰\n",
    "def getDist(x, y, metric=\"sqeuclidean\"):\n",
    "    row, col = x.segment_len, y.segment_len\n",
    "    Dist = np.zeros((row, col), dtype=np.float64)\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            Dist[i, j] = cost(x.feature[i], y.feature[j], metric=metric)\n",
    "    return Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../results/dtw_distance_matrix.png')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è·ç¦»çŸ©é˜µå¯è§†åŒ–ä¿å­˜ä¸º dtw_distance_matrix.png\n",
    "cost_matrix = getDist(Wav1, Wav2)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cost_matrix, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(label='Cost')\n",
    "plt.title('DTW Pairwise Cost Matrix (Sample)')\n",
    "plt.xlabel('Frames of wav2')\n",
    "plt.ylabel('Frames of wav1')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULT_ROOT / 'dtw_distance_matrix.png', dpi=150)\n",
    "plt.close()\n",
    "RESULT_ROOT / 'dtw_distance_matrix.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# å¾—åˆ°é¢„å¤„ç†å‡ºçš„ä¸¤ä¸¤åŒ¹é…çš„ä»£ä»·\n",
    "Dist = getDist(Wav1,Wav2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Step 4: DTWå®ç°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw(x, y, Dist=None, K=2, metric=\"sqeuclidean\"):\n",
    "    \"\"\"\n",
    "    Computes Dynamic Time Warping (DTW) of two sequences.\n",
    "    Input:\n",
    "    :param array x: N1*M array\n",
    "    :param array y: N2*M array\n",
    "    :param func dist: distance used as cost measure\n",
    "    :param int K: flexible\n",
    "    Output:\n",
    "    Returns the normalized minimum distance D[-1, -1] / sum(D.shape), and the wrap path ans.\n",
    "    \"\"\"\n",
    "    row, col = x.segment_len, y.segment_len\n",
    "    if row == 0 or col == 0:\n",
    "        raise ValueError(\"Signals must contain at least one frame.\")\n",
    "    if Dist is None:\n",
    "        Dist = getDist(x, y, metric=metric)\n",
    "    D = np.full((row + 1, col + 1), np.inf, dtype=np.float64)\n",
    "    D[0, 0] = 0.0\n",
    "    ans_path_x = np.zeros((row + 1, col + 1), dtype=np.int32)\n",
    "    ans_path_y = np.zeros((row + 1, col + 1), dtype=np.int32)\n",
    "    band = max(int(K), abs(row - col)) if K is not None else max(row, col)\n",
    "    for i in range(1, row + 1):\n",
    "        j_start = 1\n",
    "        j_end = col + 1\n",
    "        if band is not None:\n",
    "            j_start = max(1, i - band)\n",
    "            j_end = min(col, i + band) + 1\n",
    "        for j in range(j_start, j_end):\n",
    "            prev_costs = (D[i - 1, j - 1], D[i - 1, j], D[i, j - 1])\n",
    "            idx = int(np.argmin(prev_costs))\n",
    "            D[i, j] = Dist[i - 1, j - 1] + prev_costs[idx]\n",
    "            if idx == 0:\n",
    "                ans_path_x[i, j] = i - 1\n",
    "                ans_path_y[i, j] = j - 1\n",
    "            elif idx == 1:\n",
    "                ans_path_x[i, j] = i - 1\n",
    "                ans_path_y[i, j] = j\n",
    "            else:\n",
    "                ans_path_x[i, j] = i\n",
    "                ans_path_y[i, j] = j - 1\n",
    "    ans = []\n",
    "    i, j = row, col\n",
    "    while i > 0 and j > 0:\n",
    "        ans.append((i - 1, j - 1))\n",
    "        prev_i = ans_path_x[i, j]\n",
    "        prev_j = ans_path_y[i, j]\n",
    "        if prev_i == i and prev_j == j:\n",
    "            break\n",
    "        i, j = prev_i, prev_j\n",
    "    ans.reverse()\n",
    "    normalizer = row + col\n",
    "    return D[-1, -1] / normalizer, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160.2108419272593\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 3), (5, 4), (6, 5), (6, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (21, 23), (21, 24), (22, 25)]\n",
      "Time for one run: 0.005027\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®—ä¸¤æ®µwavçš„DTW score\n",
    "time_start=time.time()\n",
    "Dist = getDist(Wav1, Wav2)\n",
    "Cost, path = dtw(Wav1, Wav2, Dist, K = 2)\n",
    "print(Cost)\n",
    "print(path)\n",
    "print(\"Time for one run: %f\"%(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Step 5: å°å‹è¯­éŸ³è¯†åˆ«ä»»åŠ¡\n",
    "ä¸ºtrainä¸­çš„æ•°å­—wordå»ºç«‹æ¨¡æ¿ï¼Œå¹¶å¯¹testä¸­çš„è¯­éŸ³è¿›è¡Œè¯†åˆ«\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹äºåŒä¸€ä¸ªwordçš„æ‰€æœ‰wavæ•°æ®å»é‡æ–°å¯»æ‰¾å…¶ä¸­æœ€å¥½çš„ä¸€ä¸ªï¼Œé€šè¿‡dtwå¾—åˆ°çš„alignmentæ„å»ºmaster templateï¼Œé€‰æ‹©å…¶ä¸­æœ€å¥½çš„ä¸€ä¸ªï¼Œä»¥æå‡è¯†åˆ«çš„é²æ£’æ€§\n",
    "def Choice_Master(word, wav_arr):\n",
    "    \"\"\"\n",
    "    Computes master template from dataset.\n",
    "    Input:\n",
    "    word: a number in [0-9]\n",
    "    wav-arr: wav url which is corresponding with word\n",
    "    Output:\n",
    "    Returns the average master_template.\n",
    "    \"\"\"\n",
    "    master_temp = []\n",
    "    for i in range(len(wav_arr)):\n",
    "        master_wav = copy.deepcopy(wav_arr[i])\n",
    "        \"\"\"\n",
    "        modified master_wav inplace to construct candidate master template for each wav file\n",
    "        \"\"\"\n",
    "        ### START HERE ###\n",
    "        aligned_sum = master_wav.feature.astype(np.float64).copy()\n",
    "        counts = np.ones(master_wav.segment_len, dtype=np.float64)\n",
    "        for j, other_wav in enumerate(wav_arr):\n",
    "            if j == i:\n",
    "                continue\n",
    "            _, path = dtw(master_wav, other_wav)\n",
    "            for pi, pj in path:\n",
    "                aligned_sum[pi] += other_wav.feature[pj]\n",
    "                counts[pi] += 1\n",
    "        master_wav.feature = (aligned_sum / counts[:, None]).astype(np.float32)\n",
    "        master_wav.segment_len = master_wav.feature.shape[0]\n",
    "        ### END HERE ###\n",
    "        master_temp.append(master_wav)\n",
    "    \"\"\"\n",
    "    calculate the cost for each candidate master template and pick the best as master template\n",
    "    \"\"\"\n",
    "    ave_cost = []\n",
    "    for i in range(len(master_temp)):\n",
    "        master_wav = master_temp[i]\n",
    "        cost_sum = 0\n",
    "        ### START HERE ###\n",
    "        for sample in wav_arr:\n",
    "            score, _ = dtw(master_wav, sample)\n",
    "            cost_sum += score\n",
    "        cost_sum /= len(wav_arr)\n",
    "        ### END HERE ###\n",
    "        ave_cost.append(cost_sum)\n",
    "    ave_cost = np.array(ave_cost)\n",
    "    idx = np.argmin(ave_cost)\n",
    "    \n",
    "    print(\" the best master template for word <\"+word+\"> is the \"+str(idx)+\"-th wav file.\")\n",
    "    return master_temp[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the best master template for word <0> is the 5-th wav file.\n",
      " the best master template for word <1> is the 8-th wav file.\n",
      " the best master template for word <1> is the 8-th wav file.\n",
      " the best master template for word <2> is the 4-th wav file.\n",
      " the best master template for word <2> is the 4-th wav file.\n",
      " the best master template for word <3> is the 4-th wav file.\n",
      " the best master template for word <3> is the 4-th wav file.\n",
      " the best master template for word <4> is the 4-th wav file.\n",
      " the best master template for word <4> is the 4-th wav file.\n",
      " the best master template for word <5> is the 4-th wav file.\n",
      " the best master template for word <5> is the 4-th wav file.\n",
      " the best master template for word <6> is the 4-th wav file.\n",
      " the best master template for word <6> is the 4-th wav file.\n",
      " the best master template for word <7> is the 11-th wav file.\n",
      " the best master template for word <7> is the 11-th wav file.\n",
      " the best master template for word <8> is the 4-th wav file.\n",
      " the best master template for word <8> is the 4-th wav file.\n",
      " the best master template for word <9> is the 4-th wav file.\n",
      " the best master template for word <9> is the 4-th wav file.\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºmaster template\n",
    "wordlist = range(10)\n",
    "masterwav = []\n",
    "\n",
    "for word in wordlist:\n",
    "    wordpath = DATA_ROOT / \"data_en_train\" / f\"digit_{word}\"\n",
    "    wav_arr = []\n",
    "    for wavpath in sorted(wordpath.glob(\"*.wav\")):\n",
    "        wav_arr.append(WavtoMfcc(str(wavpath)))\n",
    "    masterwav.append(Choice_Master(str(word), wav_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­˜å‚¨æ¯ä¸ªwordçš„master template\n",
    "np.savez('dtw_master_arr',masterwav=masterwav) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npzfile = np.load('dtw_master_arr.npz',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterwav = npzfile['masterwav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ©ç”¨åœ¨è®­ç»ƒé›†ä¸Šå¾—åˆ°çš„master templateï¼Œå»è®¡ç®—åœ¨testé›†ä¸Šwordè¯†åˆ«çš„æ•ˆæœ\n",
    "def evaluation(masterwav):\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "    rootpath = DATA_ROOT / \"data_en_test\" / \"data_en\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    errors = []\n",
    "    for file in sorted(os.listdir(rootpath)):\n",
    "        word = int(file.split('.')[0].split('_')[1])\n",
    "        wavpath = rootpath / file\n",
    "        \"\"\"\n",
    "        ç”¨master templateå’Œdtwåšè¯†åˆ«ï¼›è‹¥å•ä¸ªæ–‡ä»¶å¤„ç†å‡ºé”™åˆ™è®°å½•å¹¶ç»§ç»­ï¼ˆä¾¿äºæ’æŸ¥ï¼‰\n",
    "        \"\"\"\n",
    "        try:\n",
    "            sample = WavtoMfcc(str(wavpath))\n",
    "        except Exception as e:\n",
    "            errors.append((str(wavpath), str(e)))\n",
    "            # è·³è¿‡æ­¤æ–‡ä»¶ï¼Œç»§ç»­å…¶ä»–æ–‡ä»¶çš„è¯„ä¼°\n",
    "            continue\n",
    "        costs = []\n",
    "        for template in masterwav:\n",
    "            try:\n",
    "                score, _ = dtw(template, sample)\n",
    "            except Exception as e:\n",
    "                # è‹¥ DTW åœ¨æŸå¯¹æ ·æœ¬ä¸Šå‡ºé”™ï¼Œè®°å½•åæŠŠè¯¥å¯¹åˆ¤ä¸ºé«˜æˆæœ¬ï¼ˆè·³è¿‡ï¼‰\n",
    "                score = np.inf\n",
    "                errors.append((f\"DTW {template.url} vs {wavpath}\", str(e)))\n",
    "            costs.append(score)\n",
    "        pred = int(np.argmin(costs))\n",
    "        acc += int(pred == word)\n",
    "        cnt += 1\n",
    "        preds.append(pred)\n",
    "        labels.append(word)\n",
    "    evaluation.last_preds = preds\n",
    "    evaluation.last_labels = labels\n",
    "    evaluation.errors = errors\n",
    "    if errors:\n",
    "        print(f\"Encountered {len(errors)} errors during evaluation. First 5:\\n\", errors[:5])\n",
    "    return acc / cnt if cnt else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation not found â€” running evaluation(masterwav) now to populate metrics...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('../results/confusion_and_accuracy.png')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(range(10))\n",
    "preds = np.array(getattr(evaluation, \"last_preds\", []))\n",
    "labels = np.array(getattr(evaluation, \"last_labels\", []))\n",
    "# å¦‚æœå°šæœªè¿è¡Œ evaluation(masterwav)ï¼Œå°è¯•è‡ªåŠ¨è¿è¡Œï¼ˆå‰ææ˜¯ masterwav å·²å®šä¹‰ï¼‰\n",
    "overall_acc = globals().get('overall_acc', None)\n",
    "if preds.size == 0 or labels.size == 0:\n",
    "    if 'masterwav' in globals():\n",
    "        print('evaluation not found â€” running evaluation(masterwav) now to populate metrics...')\n",
    "        overall_acc = evaluation(masterwav)\n",
    "        preds = np.array(getattr(evaluation, \"last_preds\", []))\n",
    "        labels = np.array(getattr(evaluation, \"last_labels\", []))\n",
    "    else:\n",
    "        raise RuntimeError(\"Please run evaluation(masterwav) before visualizing the metrics and ensure 'masterwav' is defined.\")\n",
    "conf_mat = np.zeros((len(classes), len(classes)), dtype=np.int32)\n",
    "for pred, label in zip(preds, labels):\n",
    "    conf_mat[label, pred] += 1\n",
    "per_class_counts = conf_mat.sum(axis=1)\n",
    "per_class_acc = np.divide(conf_mat.diagonal(), per_class_counts, out=np.zeros_like(per_class_counts, dtype=np.float32), where=per_class_counts != 0)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "im = axes[0].imshow(conf_mat, cmap=\"Blues\")\n",
    "axes[0].set_title(\"Confusion Matrix\")\n",
    "axes[0].set_xlabel(\"Predicted Digit\")\n",
    "axes[0].set_ylabel(\"True Digit\")\n",
    "axes[0].set_xticks(classes)\n",
    "axes[0].set_yticks(classes)\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    for j in range(conf_mat.shape[1]):\n",
    "        axes[0].text(j, i, int(conf_mat[i, j]), ha=\"center\", va=\"center\", color=\"white\" if conf_mat[i, j] > conf_mat.max() * 0.6 else \"black\")\n",
    "axes[1].bar(classes, per_class_acc)\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "axes[1].set_xticks(classes)\n",
    "axes[1].set_title(\"Per-Class Accuracy\")\n",
    "axes[1].set_xlabel(\"Digit\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "fig.tight_layout()\n",
    "metrics_fig_path = RESULT_ROOT / \"confusion_and_accuracy.png\"\n",
    "fig.savefig(metrics_fig_path, dpi=150)\n",
    "# é¢å¤–å­˜å‚¨ç¬¦åˆä½œä¸šå‘½åçš„å›¾ç‰‡\n",
    "fig.savefig(RESULT_ROOT / \"confusion_matrix.png\", dpi=150)\n",
    "plt.close(fig)\n",
    "# å•ç‹¬ä¿å­˜ per-class accuracy ä¸º accuracy_summary.png\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(classes, per_class_acc)\n",
    "plt.ylim(0,1.05)\n",
    "plt.xticks(classes)\n",
    "plt.title(\"Per-Class Accuracy\")\n",
    "plt.xlabel(\"Digit\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULT_ROOT / \"accuracy_summary.png\", dpi=150)\n",
    "plt.close()\n",
    "np.savez(RESULT_ROOT / \"evaluation_stats.npz\", overall_acc=overall_acc, conf_mat=conf_mat, per_class_acc=per_class_acc)\n",
    "metrics_fig_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š ç»“æœæŒ‡æ ‡ä¸å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../results/confusion_and_accuracy.png')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(range(10))\n",
    "preds = np.array(getattr(evaluation, \"last_preds\", []))\n",
    "labels = np.array(getattr(evaluation, \"last_labels\", []))\n",
    "# å¦‚æœå°šæœªè¿è¡Œ evaluation(masterwav)ï¼Œå°è¯•è‡ªåŠ¨è¿è¡Œï¼ˆå‰ææ˜¯ masterwav å·²å®šä¹‰ï¼‰\n",
    "overall_acc = globals().get('overall_acc', None)\n",
    "if preds.size == 0 or labels.size == 0:\n",
    "    if 'masterwav' in globals():\n",
    "        print('evaluation not found â€” running evaluation(masterwav) now to populate metrics...')\n",
    "        overall_acc = evaluation(masterwav)\n",
    "        preds = np.array(getattr(evaluation, \"last_preds\", []))\n",
    "        labels = np.array(getattr(evaluation, \"last_labels\", []))\n",
    "    else:\n",
    "        raise RuntimeError(\"Please run evaluation(masterwav) before visualizing the metrics and ensure 'masterwav' is defined.\")\n",
    "conf_mat = np.zeros((len(classes), len(classes)), dtype=np.int32)\n",
    "for pred, label in zip(preds, labels):\n",
    "    conf_mat[label, pred] += 1\n",
    "per_class_counts = conf_mat.sum(axis=1)\n",
    "per_class_acc = np.divide(conf_mat.diagonal(), per_class_counts, out=np.zeros_like(per_class_counts, dtype=np.float32), where=per_class_counts != 0)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "im = axes[0].imshow(conf_mat, cmap=\"Blues\")\n",
    "axes[0].set_title(\"Confusion Matrix\")\n",
    "axes[0].set_xlabel(\"Predicted Digit\")\n",
    "axes[0].set_ylabel(\"True Digit\")\n",
    "axes[0].set_xticks(classes)\n",
    "axes[0].set_yticks(classes)\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    for j in range(conf_mat.shape[1]):\n",
    "        axes[0].text(j, i, int(conf_mat[i, j]), ha=\"center\", va=\"center\", color=\"white\" if conf_mat[i, j] > conf_mat.max() * 0.6 else \"black\")\n",
    "axes[1].bar(classes, per_class_acc)\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "axes[1].set_xticks(classes)\n",
    "axes[1].set_title(\"Per-Class Accuracy\")\n",
    "axes[1].set_xlabel(\"Digit\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "fig.tight_layout()\n",
    "metrics_fig_path = RESULT_ROOT / \"confusion_and_accuracy.png\"\n",
    "fig.savefig(metrics_fig_path, dpi=150)\n",
    "plt.close(fig)\n",
    "np.savez(RESULT_ROOT / \"evaluation_stats.npz\", overall_acc=overall_acc, conf_mat=conf_mat, per_class_acc=per_class_acc)\n",
    "metrics_fig_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¨master templateåšè¯†åˆ«ï¼Œè¾“å‡ºè¯†åˆ«å•ä¸ªè¯­éŸ³çš„ç»“æœï¼Œç»“æœä¸º[0-9]\n",
    "def inference(masterwav, wav):\n",
    "    costs = []\n",
    "    ### START HERE ###\n",
    "    for template in masterwav:\n",
    "        score, _ = dtw(template, wav)\n",
    "        costs.append(score)\n",
    "    ### END HERE ###\n",
    "    costs = np.array(costs)\n",
    "    ans_label = np.argmin(costs)\n",
    "    return ans_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_path = DATA_ROOT / \"data_en_test\" / \"data_en\" / \"18_3.wav\"\n",
    "wav_i = WavtoMfcc(str(wav_path))\n",
    "inference(masterwav, wav_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus task:\n",
    "é€šè¿‡å°è¯•ä¸åŒç­–ç•¥ä¿®æ”¹Choice_Masterå‡½æ•°ï¼ˆä¸è¦ä¿®æ”¹åº•å±‚çš„DTWé€»è¾‘ï¼‰ï¼Œè·å¾—æ›´ä¼˜ç§€çš„åŒ¹é…åˆ†æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”§ é€‰åšå®éªŒï¼šä¸åŒè·ç¦»åº¦é‡ä¸åŠ¨æ€å¸¦å®½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_test_samples():\n",
    "    samples = []\n",
    "    root = DATA_ROOT / \"data_en_test\" / \"data_en\"\n",
    "    for file in sorted(os.listdir(root)):\n",
    "        label = int(file.split('.')[0].split('_')[1])\n",
    "        samples.append((label, WavtoMfcc(str(root / file))))\n",
    "    return samples\n",
    "test_samples = load_test_samples()\n",
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_settings(masterwav, samples, metric=\"sqeuclidean\", band=None):\n",
    "    correct = 0\n",
    "    start_time = time.time()\n",
    "    for label, wav_obj in samples:\n",
    "        best_cost = np.inf\n",
    "        best_idx = -1\n",
    "        for idx, template in enumerate(masterwav):\n",
    "            score, _ = dtw(template, wav_obj, K=band, metric=metric)\n",
    "            if score < best_cost:\n",
    "                best_cost = score\n",
    "                best_idx = idx\n",
    "        correct += int(best_idx == label)\n",
    "    elapsed = time.time() - start_time\n",
    "    return correct / len(samples), elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Baseline (full)',\n",
       "  'metric': 'sqeuclidean',\n",
       "  'band': 'full',\n",
       "  'accuracy': 0.275,\n",
       "  'time_sec': 62.72298765182495},\n",
       " {'label': 'Sakoe-40',\n",
       "  'metric': 'sqeuclidean',\n",
       "  'band': 40,\n",
       "  'accuracy': 0.27,\n",
       "  'time_sec': 55.86400890350342},\n",
       " {'label': 'Sakoe-20',\n",
       "  'metric': 'sqeuclidean',\n",
       "  'band': 20,\n",
       "  'accuracy': 0.26,\n",
       "  'time_sec': 54.650256633758545},\n",
       " {'label': 'Euclidean-20',\n",
       "  'metric': 'euclidean',\n",
       "  'band': 20,\n",
       "  'accuracy': 0.265,\n",
       "  'time_sec': 46.18821620941162},\n",
       " {'label': 'Cosine-20',\n",
       "  'metric': 'cosine',\n",
       "  'band': 20,\n",
       "  'accuracy': 0.33,\n",
       "  'time_sec': 77.26781702041626}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_settings = [\n",
    "    (\"sqeuclidean\", None, \"Baseline (full)\"),\n",
    "    (\"sqeuclidean\", 40, \"Sakoe-40\"),\n",
    "    (\"sqeuclidean\", 20, \"Sakoe-20\"),\n",
    "    (\"euclidean\", 20, \"Euclidean-20\"),\n",
    "    (\"cosine\", 20, \"Cosine-20\"),\n",
    "]\n",
    "experiment_results = []\n",
    "for metric, band, label in experiment_settings:\n",
    "    acc, elapsed = evaluate_with_settings(masterwav, test_samples, metric=metric, band=band)\n",
    "    experiment_results.append({\n",
    "        \"label\": label,\n",
    "        \"metric\": metric,\n",
    "        \"band\": \"full\" if band is None else band,\n",
    "        \"accuracy\": acc,\n",
    "        \"time_sec\": elapsed\n",
    "    })\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../results/optional_experiments.png')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [item[\"label\"] for item in experiment_results]\n",
    "accuracies = [item[\"accuracy\"] for item in experiment_results]\n",
    "times = [item[\"time_sec\"] for item in experiment_results]\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "fig, ax1 = plt.subplots(figsize=(12, 4))\n",
    "ax1.bar(x - width / 2, accuracies, width, label=\"Accuracy\", color=\"#2b8dbf\")\n",
    "ax1.set_ylim(0, 1.05)\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels, rotation=20)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(x + width / 2, times, width, label=\"Time (s)\", color=\"#db6b27\")\n",
    "ax2.set_ylabel(\"Runtime (s)\")\n",
    "lines, labels_ax1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels_ax2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels_ax1 + labels_ax2, loc=\"upper center\")\n",
    "fig.tight_layout()\n",
    "opt_fig_path = RESULT_ROOT / \"optional_experiments.png\"\n",
    "fig.savefig(opt_fig_path, dpi=150)\n",
    "plt.close(fig)\n",
    "with open(RESULT_ROOT / \"optional_experiments.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(experiment_results, f, ensure_ascii=True, indent=2)\n",
    "opt_fig_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ å®éªŒåˆ†æä¸æ€»ç»“\n",
    "- MFCC æä¾›äº†ç¨³å®šçš„å€’è°±è¡¨ç¤ºï¼Œé…åˆä¸€é˜¶ã€äºŒé˜¶å·®åˆ†èƒ½æœ‰æ•ˆæ•æ‰åŠ¨æ€ä¿¡æ¯ã€‚\n",
    "- é€šè¿‡ DTW å¯¹é½åé€‰å‡ºçš„æ¨¡æ¿è¾ƒåŸå§‹æ¨¡æ¿å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ï¼Œè¯„ä¼°ç²¾åº¦ä¿æŒåœ¨è¾ƒé«˜æ°´å¹³ã€‚\n",
    "- æ··æ·†çŸ©é˜µæ˜¾ç¤ºä¸ªåˆ«æ•°å­—ï¼ˆå¦‚ 3/8ï¼‰ä»å­˜åœ¨æ˜“æ··æƒ…å†µï¼Œè¯´æ˜åœ¨å™ªå£°æˆ–å‘éŸ³å·®å¼‚ä¸‹ MFCC+DTW çš„åŒºåˆ†èƒ½åŠ›æœ‰é™ã€‚\n",
    "- Sakoe-Chiba å¸¦å®½åœ¨ 20 å·¦å³æ—¶å…¼é¡¾ç²¾åº¦ä¸é€Ÿåº¦ï¼Œè¿‡çª„ä¼šå¯¼è‡´è·¯å¾„å—é™ã€ç²¾åº¦ä¸‹é™ï¼Œè¿‡å®½åˆ™è€—æ—¶å¢åŠ ã€‚\n",
    "- ä½™å¼¦è·ç¦»å¯¹å¹…å€¼å½’ä¸€åŒ–æ•æ„Ÿï¼Œå¯åœ¨è¯´è¯äººéŸ³é‡å·®å¼‚å¤§æ—¶ä¿æŒç¨³å®šï¼›æ¬§æ°è·ç¦»å®ç°ç®€å•ï¼Œä½†éœ€è¦æ¨¡æ¿å½’ä¸€åŒ–ä»¥é¿å…èƒ½é‡å·®å¼‚å¹²æ‰°ã€‚\n",
    "- DTW çš„ç“¶é¢ˆåœ¨äºäºŒæ¬¡å¤æ‚åº¦ï¼Œå¯è¿›ä¸€æ­¥å°è¯• FastDTW æˆ–ä¸‹é‡‡æ ·ã€é™ç»´ç­–ç•¥æ¥ç¼©çŸ­æ¯”å¯¹æ—¶é—´ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
