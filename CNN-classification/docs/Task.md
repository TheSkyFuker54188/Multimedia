
## 第三次作业要求

请完成 `assignment3.ipynb` 中的填空与实验，重点为 CIFAR-10 分类任务的模型设计、训练、对比与分析。

---

## 一、模型设计部分

### Task 1：自定义 CNN 模型设计与实现

- 设计并实现你自己的 CNN 网络结构，用于 CIFAR-10 分类任务。
- 模型应包含合理的卷积层、池化层、激活函数、全连接层等基本模块。
- 可选但建议尝试：BatchNorm、Dropout、Residual Connection（残差连接）等提升性能的技巧。
- 可探索项：网络深度、卷积核大小、数据增强策略（如随机裁剪、翻转、颜色抖动）等。

### Task 2：使用经典模型进行对比实验

- 选择至少一种经典 CNN（例如 AlexNet、VGG、ResNet 等）在 CIFAR-10 上训练与测试以做对比。
- 可依据实际情况选择使用预训练权重或从头训练。
- 建议（可选）：尝试多种经典模型并比较性能差异。

---

## 二、训练与测试部分

- 编写并完整实现训练循环与测试循环（包括验证/测试阶段）。
- 在训练/测试过程中记录每个 epoch 的 loss 与 accuracy。
- 可调整超参数：学习率、优化器（SGD / Adam）、学习率调度、权重衰减等以提升性能。
- 保存并绘制训练/测试曲线（loss 与 accuracy 随 epoch 变化的图表），便于结果分析与对比。

---

## 三、分析部分

- 比较自定义 CNN 与经典模型在 CIFAR-10 上的最终性能（精度、loss、参数量、训练时间等）。
- 分析自定义模型的优缺点：如结构复杂度、收敛速度、最终精度与泛化能力。
- 若尝试了不同优化策略（例如数据增强、正则化、残差连接、批归一化等），请给出这些方法对结果的影响分析。

---

## 四、提交内容

请提交以下内容：

1. 已完成并能运行的 `assignment3.ipynb`（填空已完成，能复现实验结果）。
2. 训练结果截图：包括但不限于 loss/accuracy 曲线、模型性能比较图表等。每张图应说明对应模型和实验设置。
3. 如有额外实验（如多模型比较或不同超参数设定），请附上说明或对比图表。

---

## 五、打包与命名格式

将提交文件打包为 `.zip`，命名格式：

```
assignment3_姓名_学号.zip
```

推荐的文件夹结构示例：

```
assignment3_姓名_学号/
├── notebooks/
│   └── assignment3.ipynb
├── results/
│   ├── myCNN_loss_acc_curve.png
│   ├── alexnet_loss_acc_curve.png
│   ├── vgg_loss_acc_curve.png
│   ├── resnet_loss_acc_curve.png
│   ├── comparison_accuracy.png
│   └── comparison_loss.png
└── README.txt  # （可选）简要说明模型设计思路、训练结果与性能分析
```

---

## 说明与小建议

- 建议在 `assignment3.ipynb` 中提供：模型定义、训练/验证代码、可复现的超参数（学习率、批大小、随机种子）、结果可视化与分析段落。
- 若使用预训练模型，请在 README 或 notebook 中说明所用权重来源与是否对权重进行微调（fine-tune）。
- 尽量保证 notebook 在提交环境中可直接运行（或在 README 中提供简短的运行步骤与依赖清单）。

如需我协助：可帮你检查 `assignment3.ipynb` 的填空、实现模型代码、绘图或生成 README 示例。

