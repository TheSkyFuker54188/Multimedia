{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0d007a-f54f-4e8a-8401-44d615006869",
   "metadata": {},
   "source": [
    "# Assignment1\n",
    "\n",
    "1. Simple numpy exercises.\n",
    "2. Implement K-nearest-neighbor with numpy.\n",
    "\n",
    "If you are not sure about some api, search their document. E.g., NumPy manual https://numpy.org/doc/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a8ed4-fd2c-4994-817a-2338f0f19e72",
   "metadata": {},
   "source": [
    "## 1.Simple Numpy Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d6af0-0fa0-4a4b-82b5-b83611e3a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "#### 1. How to find the most frequent value in an array?\n",
    "Z = np.random.randint(0,10,50)\n",
    "print(Z)\n",
    "########### less than two lines ###########\n",
    "##### Hint: argmax, bincount ##############\n",
    "answer = ...\n",
    "##### answer should be 9 ##################\n",
    "###########################################\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18b53e-9c8c-46dd-b35b-d8e3cb83474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. Consider a small/medium/large vector Z, compute Z to the power of 3 using 3 different methods\n",
    "#### search how to use np.einsum ####\n",
    "np.random.seed(1)\n",
    "x = np.random.rand(int(5e7))\n",
    "%timeit ... # solution A: np.einsum / from einops import einosum\n",
    "%timeit ... # solution B: np.power()\n",
    "%timeit ... # solution C\n",
    "# even more ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102dfb1-141e-461d-b590-abe37ddb5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3. Create random vector of size 10 and replace the maximum value by 0\n",
    "np.random.seed(1)\n",
    "Z = np.random.random(10)\n",
    "# your solution in one line, hint: use argmax and indexing\n",
    "answer = ...\n",
    "print(answer)\n",
    "# answer should be\n",
    "#  [4.17022005e-01 0.00000000e+00 1.14374817e-04 3.02332573e-01\n",
    "#  1.46755891e-01 9.23385948e-02 1.86260211e-01 3.45560727e-01\n",
    "#  3.96767474e-01 5.38816734e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa76f58-df95-47bc-916a-ac8f65e6c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4. Normalize a 5x5 random matrix\n",
    "#### normalize: (x - μ) / σ\n",
    "np.random.seed(1)\n",
    "Z = np.random.random((5,5))\n",
    "# your solution in one line, hint: use np.mean, np.std\n",
    "answer = ...\n",
    "print(answer)\n",
    "# answer should be: \n",
    "# [[-0.08166511  1.00240927 -1.57179097 -0.4915921  -1.04765972]\n",
    "#  [-1.24215993 -0.906462   -0.33708451 -0.15405956  0.35365788]\n",
    "#  [-0.07390005  0.87693577 -0.84143938  1.56639833 -1.47431007]\n",
    "#  [ 0.82420869 -0.08065433  0.42468899 -1.07042386 -0.86413849]\n",
    "#  [ 1.28984952  1.88859468 -0.45194809  0.90232398  1.56022104]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb08cd-cda2-4500-8926-91a113991240",
   "metadata": {},
   "source": [
    "## 3.Implement KNN with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bd405-6f6f-4406-8bad-ae37c008ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 设置 matplotlib 显示格式\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # 设置默认图像大小\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# CIFAR-10 数据集的下载和加载\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),  # 转换为 Tensor\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]  # 归一化\n",
    ")\n",
    "\n",
    "# 从零开始下载数据集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545a468f-1bdd-4779-aa04-c982b5ac7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10的分类标签\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_samples = 5\n",
    "\n",
    "# 为每个类别获取10个样本\n",
    "def get_samples_per_class(data, num_samples=10):\n",
    "    samples = {cls: [] for cls in range(len(classes))}\n",
    "    \n",
    "    for img, label in zip(data.data, data.targets):\n",
    "        if len(samples[label]) < num_samples:\n",
    "            samples[label].append(img)\n",
    "        # 当所有类都满足数量要求时，结束\n",
    "        if all(len(samples[cls]) == num_samples for cls in samples):\n",
    "            break\n",
    "    \n",
    "    return samples\n",
    "    \n",
    "# 获取每个类10个样本\n",
    "samples = get_samples_per_class(trainset, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb132e6b-dcfc-4e69-aacc-aec050c26aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制N(类别数) x 10 的figure，标注label\n",
    "def plot_samples(samples, num_classes=len(classes), samples_per_class=10):\n",
    "    fig, axes = plt.subplots(samples_per_class, num_classes, figsize=(num_classes+10, samples_per_class+3))\n",
    "    for i, (cls, imgs) in enumerate(samples.items()):\n",
    "        for j, img in enumerate(imgs):\n",
    "            ax = axes[j, i]\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(classes[cls])\n",
    "    plt.show()\n",
    "# 显示样本图像\n",
    "plot_samples(samples, samples_per_class=num_samples)\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # 打印标签\n",
    "# print(' '.join(f'{classes[labels[j]]}' for j in range(4)))\n",
    "\n",
    "# 打印训练集和测试集的大小\n",
    "print(f'Training data shape: {len(trainset)}')\n",
    "print(f'Test data shape: {len(testset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b0be0b8-a7fe-4cb3-9977-41443841f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = trainset.data[:5000], np.array(trainset.targets[:5000], dtype=int)\n",
    "X_test, y_test = testset.data[:500], np.array(testset.targets[:500])\n",
    "X_train = X_train.reshape(X_train.shape[0], np.prod(X_train.shape[1:]))\n",
    "X_test = X_test.reshape(X_test.shape[0], np.prod(X_test.shape[1:]))\n",
    "X_train = X_train / 256.\n",
    "X_test = X_test / 256."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5b12d-737a-4838-91b2-9da89b060f01",
   "metadata": {},
   "source": [
    "We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps:\n",
    "\n",
    "1. First we must compute the distances between all test examples and all train examples.\n",
    "2. Given these distances, for each test example we find the k nearest examples and have them vote for the label.\n",
    "\n",
    "Lets begin with computing the distance matrix between all training and test examples.\n",
    "\n",
    "For example, if there are Ntr training examples and Nte test examples, this stage should result in a Nte x Ntr matrix where each element (i,j) is the distance between the i-th test and j-th train example.\n",
    "\n",
    "**Note: For the three distance computations that we require you to implement in this notebook, you may not use the np.linalg.norm() function that numpy provides.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43373fae-6902-42b0-96cd-828e62fb9152",
   "metadata": {},
   "source": [
    "First, open `k_nearest_neighbor.py` and implement the function compute_distances_two_loops/compute_distances_one_loops/compute_distances_no_loops **in one line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc384200-bdb4-4a60-b0d4-80a4b2bcbeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_nearest_neighbor_answer import KNearestNeighbor\n",
    "# Create a kNN classifier instance. \n",
    "# Remember that training a kNN classifier is a noop: \n",
    "# the Classifier simply remembers the data and does no further processing \n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)\n",
    "\n",
    "# Let's compare how fast the implementations are\n",
    "def time_function(f, *args):\n",
    "    \"\"\"\n",
    "    Call a function f with args and return the time (in seconds) that it took to execute.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    tic = time.time()\n",
    "    results = f(*args)\n",
    "    toc = time.time()\n",
    "    return toc - tic, results\n",
    "\n",
    "no_loop_time, no_loop_results = time_function(classifier.compute_distances_no_loops, X_test)\n",
    "print('No loop version took %f seconds' % no_loop_time)\n",
    "\n",
    "one_loop_time, one_loop_results = time_function(classifier.compute_distances_one_loop, X_test)\n",
    "print('One loop version took %f seconds' % one_loop_time)\n",
    "\n",
    "two_loop_time, two_loop_results = time_function(classifier.compute_distances_two_loops, X_test)\n",
    "print('Two loop version took %f seconds' % two_loop_time)\n",
    "# You should see significantly faster performance with the fully vectorized implementation\n",
    "\n",
    "difference1 = np.linalg.norm(no_loop_results - one_loop_results, ord='fro')\n",
    "difference2 = np.linalg.norm(no_loop_results - two_loop_results, ord='fro')\n",
    "difference3 = np.linalg.norm(one_loop_results - two_loop_results, ord='fro')\n",
    "print(difference1, difference2, difference3)\n",
    "# You should see exactly the same of these results, all 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3f8c7-3cf4-4d50-8cc2-a5e543405b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_nearest_neighbor_answer import KNearestNeighbor\n",
    "# Create a kNN classifier instance. \n",
    "# Remember that training a kNN classifier is a noop: \n",
    "# the Classifier simply remembers the data and does no further processing \n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)\n",
    "dists = classifier.compute_distances_no_loops(X_test)\n",
    "# We can visualize the distance matrix: each row is a single test example and\n",
    "# its distances to training examples\n",
    "plt.imshow(dists, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce4305-4b04-4c51-a200-7cfce7716c92",
   "metadata": {},
   "source": [
    "**Bonus question**: You can think what does this distance matrix means, why some rows or columns are visible brighter or darker? What's the behind true reason?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d35c2d-2495-4582-ad75-3c2c5e779ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now implement the function predict_labels and run the code below:\n",
    "# We use k = 1 (which is Nearest Neighbor).\n",
    "y_test_pred = classifier.predict_labels(dists, k=1)\n",
    "num_test = len(y_test)\n",
    "# Compute and print the fraction of correctly predicted examples\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "\n",
    "y_test_pred = classifier.predict_labels(dists, k=5)\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "\n",
    "# you should see that accuracy of k == 5 is a little higher than k == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07465e-0b1e-49b0-ab28-80557f952679",
   "metadata": {},
   "source": [
    "Other distance functions are also acceptable, e.g., L1 distance, L0 distance, Lp distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a559b-d61a-477c-9353-802aeb4e683e",
   "metadata": {},
   "source": [
    "If possible, see how does KNN behave on the whole dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
